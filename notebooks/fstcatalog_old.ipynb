{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import sys\n",
                "import os\n",
                "if not any([p for p in sys.path if os.getcwd().replace('/fstcatalog/fstcatalog/notebooks','') == p]):\n",
                "    sys.path.append(os.getcwd().replace('/notebooks','/fstcatalog'))\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "from glob import glob\n",
                "from pathlib import Path\n",
                "from datetime import datetime, timedelta\n",
                "import os\n",
                "from multiprocessing import Pool, Manager\n",
                "import concurrent.futures\n",
                "import numpy as np\n",
                "\n",
                "manager = Manager()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "REJECT = set(['color', 'iau', 'fstcomp','logs','difax','xml','pds','gpkg','plot','bulletins','work', 'images', 'scribe', 'grib', 'netcdf', 'umos', 'banco', 'cutoff', 'backup', 'blacklisting', 'iweb', 'stormtrack', 'monitoring', 'edigraf', 'anal', 'trial', 'restart', 'prof'])\n",
                "META_DATA = [\"^>\", \">>\", \"^^\", \"!!\", \"!!SF\", \"HY\", \"P0\", \"PT\", \"E1\"]\n",
                "FILES = manager.list([])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_subdirectories_for_path(path):\n",
                "    subdirectories = []\n",
                "    if len([r for r in REJECT if r in path]):\n",
                "        return subdirectories\n",
                "    for entry in os.scandir(path):\n",
                "        if entry.is_dir():\n",
                "            subdirectories.append(entry.path)\n",
                "    return subdirectories\n",
                "    \n",
                "def get_subdirectories(base_path):\n",
                "    subdirectories = []\n",
                "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
                "        to_visit = [base_path]\n",
                "        while to_visit:\n",
                "            with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:\n",
                "                directories = {executor.submit(get_subdirectories_for_path, path): path for path in to_visit}\n",
                "                to_visit = []\n",
                "                for future in concurrent.futures.as_completed(directories):\n",
                "                    subdirectories_for_path = future.result()\n",
                "                    subdirectories.extend(subdirectories_for_path)\n",
                "                    to_visit.extend(subdirectories_for_path)\n",
                "\n",
                "    subdirectories = [sd for sd in subdirectories if not any([r in sd for r in REJECT])]\n",
                "    return subdirectories\n",
                "\n",
                "def maybeFST(filename) -> bool:\n",
                "    if not os.path.isfile(filename):\n",
                "        return False\n",
                "    with open(filename, 'rb') as f:\n",
                "        buf = f.read(16)\n",
                "        if len(buf) < 16:\n",
                "            return False\n",
                "        # Same check as c_wkoffit in librmn\n",
                "        return buf[12:] == b'STDR'\n",
                "\n",
                "def get_days(num_days):\n",
                "    today = datetime.today()\n",
                "    dates = [today + timedelta(days=i) for i in range(num_days + 1)]\n",
                "    return [date.strftime(\"%d\") for date in dates]\n",
                "\n",
                "def find_files(base_path, num_days = 3):\n",
                "    now = datetime.now()\n",
                "    fst_files = []\n",
                "    for day in get_days(num_days):\n",
                "        pattern = f\"**/{now.year}{now.month:02d}{day}[0-9][0-9]_[0-9][0-9][0-9]\"\n",
                "        fst_files.extend(glob(f'{base_path}/{pattern}', recursive = True))\n",
                "    FILES.extend(fst_files)    \n",
                "    # return fst_files\n",
                "    \n",
                "def raw_headers(filename):\n",
                "    # if not os.path.exists(filename):\n",
                "    #   return None\n",
                "    f = open(filename,'rb')\n",
                "    # # Use same check as maybeFST\n",
                "    # magic = f.read(16)\n",
                "    # if len(magic) < 16 or magic[12:] != b'STDR':\n",
                "    #     f.close()\n",
                "    #     return None\n",
                "    # Get the raw (packed) parameters.\n",
                "    pageaddr = 27\n",
                "    raw = []\n",
                "\n",
                "    while pageaddr > 0:\n",
                "        f.seek(pageaddr*8-8, 0)\n",
                "        page = np.fromfile(f, '>i4', 8+256*18)\n",
                "        params = page[8:].reshape(256,9,2)\n",
                "        nent = page[5]\n",
                "        raw.append(params[:nent].view('B').flatten())\n",
                "        pageaddr = page[4]\n",
                "\n",
                "    res = np.concatenate(raw)\n",
                "    f.close()\n",
                "    return res\n",
                "\n",
                "\n",
                "def decode_headers(raw):\n",
                "    raw = raw.view('>i4').astype('uint32').reshape(-1,9,2)\n",
                "    nrecs = raw.shape[0]\n",
                "    out = {}\n",
                "\n",
                "\n",
                "    out['nomvar'] = np.empty(nrecs, dtype='|S4')\n",
                "    out['typvar'] = np.empty(nrecs, dtype='|S2')\n",
                "    out['etiket'] = np.empty(nrecs, dtype='|S12')\n",
                "    out['ni'] = np.empty(nrecs, dtype='int32')\n",
                "    out['nj'] = np.empty(nrecs, dtype='int32')\n",
                "    out['nk'] = np.empty(nrecs, dtype='int32')\n",
                "    out['dateo'] = np.empty(nrecs, dtype='int32')\n",
                "    out['ip1'] = np.empty(nrecs, dtype='int32')\n",
                "    out['ip2'] = np.empty(nrecs, dtype='int32')\n",
                "    out['ip3'] = np.empty(nrecs, dtype='int32')\n",
                "    out['deet'] = np.empty(nrecs, dtype='int32')\n",
                "    out['npas'] = np.empty(nrecs, dtype='int32')\n",
                "    out['datyp'] = np.empty(nrecs, dtype='ubyte')\n",
                "    out['nbits'] = np.empty(nrecs, dtype='byte')\n",
                "    out['grtyp'] = np.empty(nrecs, dtype='|S1')\n",
                "    out['ig1'] = np.empty(nrecs, dtype='int32')\n",
                "    out['ig2'] = np.empty(nrecs, dtype='int32')\n",
                "    out['ig3'] = np.empty(nrecs, dtype='int32')\n",
                "    out['ig4'] = np.empty(nrecs, dtype='int32')\n",
                "    out['datev'] = np.empty(nrecs, dtype='int32')\n",
                "    out['lng'] = np.empty(nrecs, dtype='int32')\n",
                "    out['dltf'] = np.empty(nrecs, dtype='ubyte')\n",
                "    out['swa'] =  np.empty(nrecs, dtype='uint32')\n",
                "    out['ubc'] = np.empty(nrecs, dtype='uint16')\n",
                "    # out['key'] = np.empty(nrecs, dtype='int32')\n",
                "\n",
                "    temp8 = np.empty(nrecs, dtype='ubyte')\n",
                "    temp32 = np.empty(nrecs, dtype='int32')\n",
                "\n",
                "    np.divmod(raw[:,0,0],2**24, temp8, out['lng'])\n",
                "    out['lng'] *= 2 # Convert from 8-byte to 4-byte units.\n",
                "    np.divmod(temp8,128, out['dltf'], temp8)\n",
                "    out['swa'][:] = raw[:,0,1]\n",
                "    np.divmod(raw[:,1,0],256, out['deet'], out['nbits'])\n",
                "    np.divmod(raw[:,1,1],256, out['ni'], out['grtyp'].view('ubyte'))\n",
                "    np.divmod(raw[:,2,0],256, out['nj'], out['datyp'])\n",
                "    np.divmod(raw[:,2,1],4096, out['nk'], out['ubc'])\n",
                "    out['npas'][:] = raw[:,3,0]//64\n",
                "    np.divmod(raw[:,3,1],256, out['ig4'], temp32)\n",
                "    out['ig2'][:] = (temp32 << 16) # ig2a\n",
                "    np.divmod(raw[:,4,0],256, out['ig1'], temp32)\n",
                "    out['ig2'] |= (temp32 << 8) # ig2b\n",
                "    np.divmod(raw[:,4,1],256, out['ig3'], temp32)\n",
                "    out['ig2'] |= temp32 # ig2c\n",
                "    etik15 = raw[:,5,0]//4\n",
                "    etik6a = raw[:,5,1]//4\n",
                "    et = raw[:,6,0]//256\n",
                "    etikbc, _typvar = divmod(et, 4096)\n",
                "    _nomvar = raw[:,6,1]//256\n",
                "    np.divmod(raw[:,7,0],16, out['ip1'], temp8)\n",
                "    out['ip2'][:] = raw[:,7,1]//16\n",
                "    out['ip3'][:] = raw[:,8,0]//16\n",
                "    date_stamp = raw[:,8,1]\n",
                "    # Reassemble and decode.\n",
                "    # (Based on fstd98.c)\n",
                "    etiket_bytes = np.empty((nrecs,12),dtype='ubyte')\n",
                "    for i in range(5):\n",
                "        etiket_bytes[:,i] = ((etik15 >> ((4-i)*6)) & 0x3f) + 32\n",
                "    for i in range(5,10):\n",
                "        etiket_bytes[:,i] = ((etik6a >> ((9-i)*6)) & 0x3f) + 32\n",
                "    etiket_bytes[:,10] = ((etikbc >> 6) & 0x3f) + 32\n",
                "    etiket_bytes[:,11] = (etikbc & 0x3f) + 32\n",
                "    out['etiket'][:] = etiket_bytes.flatten().view('|S12')\n",
                "    nomvar_bytes = np.empty((nrecs,4),dtype='ubyte')\n",
                "    for i in range(4):\n",
                "      nomvar_bytes[:,i] = ((_nomvar >> ((3-i)*6)) & 0x3f) + 32\n",
                "    out['nomvar'][:] = nomvar_bytes.flatten().view('|S4')\n",
                "    typvar_bytes = np.empty((nrecs,2),dtype='ubyte')\n",
                "    typvar_bytes[:,0] = ((_typvar >> 6) & 0x3f) + 32\n",
                "    typvar_bytes[:,1] = ((_typvar & 0x3f)) + 32\n",
                "    out['typvar'][:] = typvar_bytes.flatten().view('|S2')\n",
                "    out['datev'][:] = (date_stamp >> 3) * 10 + (date_stamp & 0x7)\n",
                "    # Note: this dateo calculation is based on my assumption that\n",
                "    # the raw stamps increase in 5-second intervals.\n",
                "    # Doing it this way to avoid a gazillion calls to incdat.\n",
                "    date_stamp = date_stamp - (out['deet']*out['npas'])//5\n",
                "    out['dateo'][:] = (date_stamp >> 3) * 10 + (date_stamp & 0x7)\n",
                "    # out['xtra1'][:] = out['datev']\n",
                "    # out['xtra2'][:] = 0\n",
                "    # out['xtra3'][:] = 0\n",
                "    out['nomvar'] = np.char.strip(out['nomvar'].astype('str'))\n",
                "    out['typvar'] = np.char.strip(out['typvar'].astype('str'))\n",
                "    out['etiket'] = np.char.strip(out['etiket'].astype('str'))\n",
                "    out['grtyp'] = np.char.strip(out['grtyp'].astype('str'))\n",
                "    df = pd.DataFrame(out)\n",
                "\n",
                "  # df['path'] = path\n",
                "\n",
                "    df = df.loc[df.dltf == 0]\n",
                "    df = df.drop(labels=['dltf', 'ubc'], axis=1)\n",
                "\n",
                "    df['shape'] = pd.Series(zip(df.ni.to_numpy(),df.nj.to_numpy()),dtype='object').to_numpy()\n",
                "  \n",
                "    return df\n",
                "\n",
                "def fstindex_to_pandas(filename):\n",
                "    if maybeFST(filename):\n",
                "        raw = raw_headers(filename)\n",
                "        df = decode_headers(raw)\n",
                "        df['path'] = filename\n",
                "        return df    \n",
                "    return None"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "base_path = Path('/home/smco500/cmcprod/ppp5/suites/gdps/g1')\n",
                "subdirectories = get_subdirectories(str(base_path))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "with Pool(10) as p:\n",
                "    p.map(find_files, subdirectories)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.DataFrame([{'base_path':Path(f).parent, 'path':f} for f in sorted(set(FILES))])\n",
                "# df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "DATAFRAMES = manager.list([])\n",
                "def get_records(filename):\n",
                "    DATAFRAMES.append(fstindex_to_pandas(filename))\n",
                "\n",
                "groups = df.groupby('base_path')\n",
                "for base_path, sub_df in groups:\n",
                "    with Pool(10) as p:\n",
                "        p.map(get_records, sub_df.path.to_list())\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.concat(list(DATAFRAMES))\n",
                "df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "import fstcatalog\n",
                "from glob import glob\n",
                "import datetime\n",
                "from pathlib import Path"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "current_date = datetime.datetime.now()\n",
                "year_month_string = current_date.strftime('%Y%m')\n",
                "\n",
                "base_path1 = Path('/home/smco500/cmcprod/ppp5/suites/gdps/g1/gridpt.usr/prog/eta')\n",
                "base_path2 = Path('/home/smco500/cmcprod/ppp5/suites/gdps/g1/gridpt.usr/prog/diag')\n",
                "base_path3 = Path('/home/smco500/cmcprod/ppp5/suites/gdps/g1/gridpt.usr/prog/pres')\n",
                "files = glob(f'{base_path1}/{year_month_string}0100_00*')\n",
                "files.extend(glob(f'{base_path2}/{year_month_string}0100_*'))\n",
                "files.extend(glob(f'{base_path3}/{year_month_string}0100_*'))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "filtered_files = fstcatalog.get_fst_files(files)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Processing 346 files...\n"
                    ]
                },
                {
                    "ename": "ValueError",
                    "evalue": "Must have equal len keys and value when setting with an iterable",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mLossySetitemError\u001b[0m                         Traceback (most recent call last)",
                        "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/pandas/core/frame.py:4212\u001b[0m, in \u001b[0;36mDataFrame._set_value\u001b[0;34m(self, index, col, value, takeable)\u001b[0m\n\u001b[1;32m   4211\u001b[0m     iindex \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex\u001b[39m.\u001b[39mget_loc(index)\n\u001b[0;32m-> 4212\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mcolumn_setitem(icol, iindex, value, inplace\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   4213\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_clear_item_cache()\n",
                        "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/pandas/core/internals/managers.py:1389\u001b[0m, in \u001b[0;36mBlockManager.column_setitem\u001b[0;34m(self, loc, idx, value, inplace)\u001b[0m\n\u001b[1;32m   1388\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[0;32m-> 1389\u001b[0m     col_mgr\u001b[39m.\u001b[39;49msetitem_inplace(idx, value)\n\u001b[1;32m   1390\u001b[0m \u001b[39melse\u001b[39;00m:\n",
                        "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/pandas/core/internals/managers.py:2102\u001b[0m, in \u001b[0;36mSingleBlockManager.setitem_inplace\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   2100\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cache\u001b[39m.\u001b[39mclear()\n\u001b[0;32m-> 2102\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49msetitem_inplace(indexer, value)\n",
                        "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/pandas/core/internals/base.py:188\u001b[0m, in \u001b[0;36mSingleDataManager.setitem_inplace\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(arr, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m    186\u001b[0m     \u001b[39m# Note: checking for ndarray instead of np.dtype means we exclude\u001b[39;00m\n\u001b[1;32m    187\u001b[0m     \u001b[39m#  dt64/td64, which do their own validation.\u001b[39;00m\n\u001b[0;32m--> 188\u001b[0m     value \u001b[39m=\u001b[39m np_can_hold_element(arr\u001b[39m.\u001b[39;49mdtype, value)\n\u001b[1;32m    190\u001b[0m arr[indexer] \u001b[39m=\u001b[39m value\n",
                        "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/pandas/core/dtypes/cast.py:1985\u001b[0m, in \u001b[0;36mnp_can_hold_element\u001b[0;34m(dtype, element)\u001b[0m\n\u001b[1;32m   1984\u001b[0m     \u001b[39m# Anything other than integer we cannot hold\u001b[39;00m\n\u001b[0;32m-> 1985\u001b[0m     \u001b[39mraise\u001b[39;00m LossySetitemError\n\u001b[1;32m   1986\u001b[0m \u001b[39melif\u001b[39;00m (\n\u001b[1;32m   1987\u001b[0m     dtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mu\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1988\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(element, np\u001b[39m.\u001b[39mndarray)\n\u001b[1;32m   1989\u001b[0m     \u001b[39mand\u001b[39;00m element\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mi\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1990\u001b[0m ):\n\u001b[1;32m   1991\u001b[0m     \u001b[39m# see test_where_uint64\u001b[39;00m\n",
                        "\u001b[0;31mLossySetitemError\u001b[0m: ",
                        "\nDuring handling of the above exception, another exception occurred:\n",
                        "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fstcatalog\u001b[39m.\u001b[39;49mfst_index(filtered_files)\n",
                        "File \u001b[0;32m/fs/homeu2/eccc/cmd/cmdw/sbf000/src/fstcatalog/fstcatalog.py:64\u001b[0m, in \u001b[0;36mfst_index\u001b[0;34m(files, num_proc)\u001b[0m\n\u001b[1;32m     62\u001b[0m newdf\u001b[39m.\u001b[39mat[\u001b[39m0\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mlevel\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msort(ndf\u001b[39m.\u001b[39mlevel\u001b[39m.\u001b[39munique())\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m)\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m     63\u001b[0m newdf\u001b[39m.\u001b[39mat[\u001b[39m0\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mip1\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msort(ndf\u001b[39m.\u001b[39mip1\u001b[39m.\u001b[39munique())\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m)\u001b[39m.\u001b[39mtolist()\n\u001b[0;32m---> 64\u001b[0m newdf\u001b[39m.\u001b[39;49mat[\u001b[39m0\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mip2\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msort(ndf\u001b[39m.\u001b[39mip2\u001b[39m.\u001b[39munique())\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m)\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m     65\u001b[0m newdf\u001b[39m.\u001b[39mat[\u001b[39m0\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mip3\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msort(ndf\u001b[39m.\u001b[39mip3\u001b[39m.\u001b[39munique())\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m)\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m     66\u001b[0m newdf\u001b[39m.\u001b[39mat[\u001b[39m0\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mdate_of_observation\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msort(ndf\u001b[39m.\u001b[39mdate_of_observation\u001b[39m.\u001b[39munique())\u001b[39m.\u001b[39mastype(\u001b[39mstr\u001b[39m)\u001b[39m.\u001b[39mtolist()\n",
                        "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/pandas/core/indexing.py:2442\u001b[0m, in \u001b[0;36m_AtIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39mloc[key] \u001b[39m=\u001b[39m value\n\u001b[1;32m   2440\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m-> 2442\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__setitem__\u001b[39;49m(key, value)\n",
                        "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/pandas/core/indexing.py:2397\u001b[0m, in \u001b[0;36m_ScalarAccessIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   2394\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(key) \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mndim:\n\u001b[1;32m   2395\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNot enough indexers for scalar access (setting)!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 2397\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mobj\u001b[39m.\u001b[39;49m_set_value(\u001b[39m*\u001b[39;49mkey, value\u001b[39m=\u001b[39;49mvalue, takeable\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_takeable)\n",
                        "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/pandas/core/frame.py:4224\u001b[0m, in \u001b[0;36mDataFrame._set_value\u001b[0;34m(self, index, col, value, takeable)\u001b[0m\n\u001b[1;32m   4222\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39miloc[index, col] \u001b[39m=\u001b[39m value\n\u001b[1;32m   4223\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4224\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mloc[index, col] \u001b[39m=\u001b[39m value\n\u001b[1;32m   4225\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_item_cache\u001b[39m.\u001b[39mpop(col, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m   4227\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidIndexError \u001b[39mas\u001b[39;00m ii_err:\n\u001b[1;32m   4228\u001b[0m     \u001b[39m# GH48729: Seems like you are trying to assign a value to a\u001b[39;00m\n\u001b[1;32m   4229\u001b[0m     \u001b[39m# row when only scalar options are permitted\u001b[39;00m\n",
                        "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/pandas/core/indexing.py:818\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[1;32m    817\u001b[0m iloc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39miloc\u001b[39m\u001b[39m\"\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39miloc\n\u001b[0;32m--> 818\u001b[0m iloc\u001b[39m.\u001b[39;49m_setitem_with_indexer(indexer, value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n",
                        "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/pandas/core/indexing.py:1795\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1792\u001b[0m \u001b[39m# align and set the values\u001b[39;00m\n\u001b[1;32m   1793\u001b[0m \u001b[39mif\u001b[39;00m take_split_path:\n\u001b[1;32m   1794\u001b[0m     \u001b[39m# We have to operate column-wise\u001b[39;00m\n\u001b[0;32m-> 1795\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_setitem_with_indexer_split_path(indexer, value, name)\n\u001b[1;32m   1796\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1797\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_single_block(indexer, value, name)\n",
                        "File \u001b[0;32m~/.conda/envs/py39/lib/python3.9/site-packages/pandas/core/indexing.py:1850\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer_split_path\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1845\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(value) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_integer(info_axis):\n\u001b[1;32m   1846\u001b[0m         \u001b[39m# This is a case like df.iloc[:3, [1]] = [0]\u001b[39;00m\n\u001b[1;32m   1847\u001b[0m         \u001b[39m#  where we treat as df.iloc[:3, 1] = 0\u001b[39;00m\n\u001b[1;32m   1848\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_with_indexer((pi, info_axis[\u001b[39m0\u001b[39m]), value[\u001b[39m0\u001b[39m])\n\u001b[0;32m-> 1850\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1851\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMust have equal len keys and value \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1852\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mwhen setting with an iterable\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1853\u001b[0m     )\n\u001b[1;32m   1855\u001b[0m \u001b[39melif\u001b[39;00m lplane_indexer \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(value) \u001b[39m==\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39mindex):\n\u001b[1;32m   1856\u001b[0m     \u001b[39m# We get here in one case via .loc with a all-False mask\u001b[39;00m\n\u001b[1;32m   1857\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
                        "\u001b[0;31mValueError\u001b[0m: Must have equal len keys and value when setting with an iterable"
                    ]
                }
            ],
            "source": [
                "fstcatalog.fst_index(filtered_files)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "MultiIndex([(  '2Z', 'P',   'EDYNTRP',   69,   51, 1, 'N',     '620390', ...),\n",
                            "            (  '5P', 'P', 'G1_8_1_0N', 1801, 1251, 1, 'Z', '6883990098', ...),\n",
                            "            (  'AB', 'P', 'G1_8_1_0N', 1801, 1251, 1, 'Z', '6883990098', ...),\n",
                            "            ( 'ABE', 'P', 'G1_8_1_0N', 1801, 1251, 1, 'Z', '6883990098', ...),\n",
                            "            (  'AD', 'P', 'G1_8_1_0N', 1801, 1251, 1, 'Z', '6883990098', ...),\n",
                            "            (  'AE', 'P', 'G1_8_1_0N', 1801, 1251, 1, 'Z', '6883990098', ...),\n",
                            "            ('AFSD', 'P', 'G1_8_1_0N', 1801, 1251, 1, 'Z', '6883990098', ...),\n",
                            "            ('AFSF', 'P', 'G1_8_1_0N', 1801, 1251, 1, 'Z', '6883990098', ...),\n",
                            "            ('AFSI', 'P', 'G1_8_1_0N', 1801, 1251, 1, 'Z', '6883990098', ...),\n",
                            "            ('AFSV', 'P', 'G1_8_1_0N', 1801, 1251, 1, 'Z', '6883990098', ...),\n",
                            "            ...\n",
                            "            (  'WH', 'P', 'G1WE_2_0X', 1801, 1251, 1, 'Z', '6883990098', ...),\n",
                            "            (  'WT', 'P', 'G1_8_1_0N', 1801, 1251, 1, 'Z', '6883990098', ...),\n",
                            "            (  'WW', 'P', 'G1_8_1_0N', 1801, 1251, 1, 'Z', '6883990098', ...),\n",
                            "            (  'WW', 'P', 'G1_8_1_0N', 1801, 1251, 1, 'Z', '6883990098', ...),\n",
                            "            (  'Z0', 'P', 'G1_8_1_0N', 1801, 1251, 1, 'Z', '6883990098', ...),\n",
                            "            ( 'ZEL', 'P', 'G1CNVEGYN', 1801, 1251, 1, 'Z', '6883990098', ...),\n",
                            "            ( 'ZFC', 'P', 'G1CNVEGYN', 1801, 1251, 1, 'Z', '6883990098', ...),\n",
                            "            ('ZLCL', 'P', 'G1LCONDLN', 1801, 1251, 1, 'Z', '6883990098', ...),\n",
                            "            ( 'ZVC', 'P', 'G1CNVEGYN', 1801, 1251, 1, 'Z', '6883990098', ...),\n",
                            "            ( 'ZVE', 'P', 'G1CNVEGYN', 1801, 1251, 1, 'Z', '6883990098', ...)],\n",
                            "           names=['nomvar', 'typvar', 'etiket', 'ni', 'nj', 'nk', 'grtyp', 'grid', 'vctype'], length=281)"
                        ]
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# import pandas as pd\n",
                "# pd.set_option('display.max_rows', 1000)\n",
                "# pd.set_option('display.max_columns', 1000)\n",
                "df.index.get_level_values(2).unique().to_list()\n",
                "df.index\n",
                "# df.loc[df.nomvar == 'ES']\n",
                "# nomvar typvar     etiket    ni    nj  nk      dateo    ip1    ip2  ip3  deet  npas datyp  nbits grtyp    ig1    ig2    ig3    ig4\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df = fstcatalog.remove_meta(df)\n",
                "\n",
                "# np.sort(df.nomvar.unique())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df.columns\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "df2 = df.set_index(['nomvar','etiket','ni','nj', 'nk', 'grtyp', 'grid', 'vctype'])\n",
                "df2"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import fstpy\n",
                "display(filtered_files[0])\n",
                "df1 = fstpy.StandardFileReader(filtered_files[0]).to_pandas()\n",
                "fstpy.voir(df1)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import fstd2nc\n",
                "ds = fstd2nc.Buffer(df.loc[df.nomvar == 'TD'].path.tolist(), vars=['TD']).to_xarray()\n",
                "ds\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.9"
        },
        "vscode": {
            "interpreter": {
                "hash": "931f9e18074b18a2c5e86a330b8a1fb7e8011ae10c9a94e830dbd2f30784ebfe"
            }
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
